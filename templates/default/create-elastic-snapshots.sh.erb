#!/usr/bin/env bash
#set -x
#
# DESCRIPTION
#   create-elastic-snapshots.sh.erb
#   NOTE: this is managed by chef changes here will be overwritten next chef-client run
#
#   Connects to elasticsearch API via kibana (coordinating node) or another cluster node
#     using TLS/SSL, user credentials, etc.
#   Thanks to and based on / inspired by what I saw out there, including:
#       Karel Bemelman's Elasticsearch backup script with snapshot rotation
#         ref: https://www.karelbemelmans.com/2015/03/elasticsearch-backup-script-with-snapshot-rotation/
#       Cloudbees Managing snapshots of your Elasticsearch indices:
#         ref: https://support.cloudbees.com/hc/en-us/articles/115000592472-Managing-snapshots-of-your-Elasticsearch-indices-
#
# REQUIREMENTS
#   Snapshot repos must already exist--we want to keep standards for managing snapshots etc.
#
#   CURL_CA_BUNDLE ENV var exported / set to the valid (CA) cert for cluster access (required for x-pack ES 6.x+)
#     i.e.: export CURL_CA_BUNDLE="$HOME/certs/elasticsearch/prod1/ca/ca.crt"
#
#   Elasticsearch (sadly admin) user with requisite creds ref: https://github.com/elastic/elasticsearch/issues/29725#
#     Create requisite Elasticsearch role (ref: very helpful plugin doc https://docs.search-guard.com/latest/snapshot-restore)
#         POST /_xpack/security/role/manage_snapshots
#         {
#           "cluster": [ "cluster:admin/repository/put","cluster:admin/repository/get","cluster:admin/snapshot/status","cluster:admin/snapshot/get","cluster:admin/snapshot/create","cluster:admin/snapshot/restore","cluster:admin/snapshot/delete"],
#           "indices": [
#             {
#               "names": [ "*" ],
#               "privileges": ["write","read","create"]
#             }
#           ]
#         }
#
#   S3 Repo Exists for cluster
#   Create the requisite snapshot repos with the following PUT commands
#
#   # PROD cluster should use prod1
#       PUT _snapshot/prod1
#       {
#         "type": "s3",
#         "settings": {
#           "bucket": "terradatum-elasticsearch",
#           "chunk_size": "1gb",
#           "base_path": "snapshots6x/prod/prod1",
#           "storage_class": "standard"
#         }
#       }
#
#   # DEV cluster should use dev1
#       PUT _snapshot/dev1
#       {
#         "type": "s3",
#         "settings": {
#           "bucket": "terradatum-elasticsearch",
#           "chunk_size": "1gb",
#           "base_path": "snapshots6x/dev/dev1",
#           "storage_class": "standard"
#         }
#       }
#
#   Requisite cluster vars file exists to source for this script to source when running (from cron).
#   This cluster-specific vars file is dynamically managed via chef for each distinct cluster/ENV.
#
#     #!/usr/bin/env bash
#     Note this is managed by chef changes here will be overwritten next chef-client run
#     export ES_USR=<%= @es_user %>
#     export ES_PASSWD=<%= @es_passwd %>
#     # LIMIT must be >= 1
#     export LIMIT=<%= @snapshot_limit %>
#     # When running remotely from my OSX workstation
#     if [[ "$(uname)" = "Darwin" ]]; then
#       export CURL_CA_BUNDLE="$HOME/certs/elasticsearch/prod1/ca/ca.crt"
#     else
#       # Our CentOS ES servers will all have their CA certs here
#       export CURL_CA_BUNDLE="/etc/elasticsearch/certs/ca.crt"
#     fi
#     #export ES_URL="https://kibana1.terradatum.com:9200" # i.e.: prod
#     #export ES_URL="https://kibana1.dev.terradatum.com:9200" # i.e.: dev
#     export ES_URL=<%= @es_url %>
#
#   Usage:
#     This was created for our org's use, managed by chef, and configured and run by cron on the Kibana coordinating node.
#     They can run remotely provided the ENV has requisite access to ES API, user creds, CA certs, etc.
#     i.e.:
#       cat /etc/cron.d/prod-create-elastic-snapshots
#       # Generated by Chef. Changes will be overwritten.
#       # 1 9 * * * root /opt/td-elastic-utilties/create-elastic-snapshots.sh -n prod1 -r prod1 -s snapshot-nightly -v # verbose option lists indices included in snapshot

usage() { 
  printf '\nUsage: $0 [-n <CLUSTER_NAME> ] [-r <REPO_NAME> ] [-s <SNAPSHOT_NAME> ] \n' 
    printf '\nExample usage:\n\n\t$0 -n prod1 -r prod1 -s snapshot_foo -v\n' # Use '-v' for verbose output; our cluster name is the same as the main s3 snapshot repo name
    exit 1
}

while getopts ":n:r:s:v" o; do
    case "${o}" in
        n)
            n=${OPTARG}
            export CLUSTER_NAME=${OPTARG}
            echo "CLUSTER_NAME: ${CLUSTER_NAME}"
            ;;

        r)
            r=${OPTARG}
            export REPO_NAME=${OPTARG}
            echo "REPO_NAME: ${REPO_NAME}"
            ;;

        s)
            s=${OPTARG}
            export SNAPSHOT_PREFIX=${OPTARG}
            echo "SNAPSHOT_PREFIX: ${SNAPSHOT_PREFIX}"
            ;;

        v)
            v=${OPTARG}
            export VERBOSE_FLAG="true"
            echo "VERBOSE_FLAG: ${VERBOSE_FLAG}"
            ;;

        *)
            usage
            ;;

    esac
done
shift $((OPTIND-1))

BASE_DIR="$(dirname "$0")"

TIMESTAMP=$(date +%Y%m%d-%H%M%S)

SNAPSHOT_NAME="${SNAPSHOT_PREFIX}-${TIMESTAMP}"

if [[ "${CLUSTER_NAME}" == "prod1" ]]; then
    echo 'sourcing $BASE_DIR/prod1-cluster-vars'
    source $BASE_DIR/prod1-cluster-vars
    export ES_URL="https://kibana1.terradatum.com:9200"
    #env | egrep "(ES_USR|ES_PASSWD|URL|CA)"
elif [[ "${CLUSTER_NAME}" == "dev1" ]]; then
    echo 'sourcing $BASE_DIR/dev1-cluster-vars'
    source $BASE_DIR/dev1-cluster-vars
    export ES_URL="https://kibana1.dev.terradatum.com:9200"
    #env | egrep "(ES_USR|ES_PASSWD|URL|CA)"
else
    echo "${CLUSTER_NAME} not recognized please use either 'prod1' or 'dev1'"
    usage
fi

# Bail and bark if we dont know the CLUSTER_NAME repo_name snapshot_name
if [ -z "${n}" ] || [ -z "${r}" ] || [ -z "${s}" ]; then
    usage
fi

# to see the indices included in snapshot use the '-v' flag else you will just see { "accepted": true }
if [[ "${VERBOSE_FLAG}" == "true" ]]; then
    curl -u ${ES_USR}:${ES_PASSWD} -XPUT "${ES_URL}/_snapshot/${REPO_NAME}/${SNAPSHOT_NAME}?wait_for_completion=true" -d ' { "ignore_unavailable": true, "include_global_state": true }' -H 'Content-Type: application/json' --silent | jq .
else
    curl -u ${ES_USR}:${ES_PASSWD} -XPUT "${ES_URL}/_snapshot/${REPO_NAME}/${SNAPSHOT_NAME}?pretty" -d ' { "ignore_unavailable": true, "include_global_state": true }' -H 'Content-Type: application/json' --silent | jq .
fi

